import argparse
import sys
sys.path.append(r'C:\Users\DAA426\myWork\objectDetection-learning\classifier') # at some point, this should become import classifier when it will be made as a package and installed)
from classifier.architectures import classification 
import configparser
from PIL import Image 
import torch
import torchvision
from classifier.dataLoader.image import classificationDataSet
import pathlib
from torch.utils.data import DataLoader
import torch.optim as optim
import torch.nn as nn

# TODO This script is Work in Progress
# it should be converted to exploit hand-written digits based on trained MNIST model
# at the moment it just proposes syntax for a classification-based model 
# but is not backed by a properly trained architecture

if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='exploit network',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument('-f', '--filepath', help='image filepath', default='./data/raw/exploiting')
    parser.add_argument('-cfg', '--configuration', help='Neural Network Configuration File', required=True)
    args = parser.parse_args()

    # Parse arguments
    configFile = args.configuration

    # Parse configuration file
    config = configparser.ConfigParser(inline_comment_prefixes="#")
    config.read(configFile)
    
    architecture = config['ARCHITECTURE']['architecture'] 
    optimizer = config['OPTIMIZER']['optimizer']
    loss = config['OPTIMIZER']['loss']
    if architecture == "LeNet5":
         arch = classification.LeNet5()
    if optimizer == "sgd":
        optimizer = optim.SGD(arch.parameters(), lr=0.001, momentum=0.9)
    if loss == "crossentropy":
        lossCompute = nn.CrossEntropyLoss()

    dataPath = pathlib.Path(args.filepath)

    # Set computation device
    device = torch.device('cpu')

    # create dataset
    # note that pytorch transforms are nice since already there for use
    # BUT apparently PyTorch does not provide transforms that acts on the labels as well
    # so for detection tasks one has to write its own transforms
    transform = torchvision.transforms.Compose([torchvision.transforms.Resize((32,32)),
                                               torchvision.transforms.Grayscale(num_output_channels=1)])
    transformedDataset = classificationDataSet(dataPath, transform)

    # just take a look
    for sample in transformedDataset:
        toPil = torchvision.transforms.ToPILImage() # mode will be deduced
        toPil(sample['image']).show(title='sample {}'.format(sample['label']))

    # create a loader to handle loading of data and potentially
    # multiprocessing
    dataloader = DataLoader(transformedDataset, batch_size=4,
                            shuffle=True, num_workers=1)

    def humanLabelToComputerLabel(labels):
        map_table = {'dog':0}
        # note : torch.Tensor also exists and is an alias for torch.FloatTensor
        # important to specify long type since crossEntropy loss expects
        # class labels so integers and not float !
        return torch.tensor([map_table[label] for label in labels], dtype=torch.long)

    # prepare optimization loop
    for epoch in range(10):
        running_loss = 0.0
        for i, data in enumerate(dataloader):
            # split labels & inputs
            inputs, labels = data.values()

            # zero the parameter gradients
            optimizer.zero_grad()

            # forward + backward + optimize
            outputs = arch(inputs)
            loss = lossCompute(outputs, humanLabelToComputerLabel(labels))
            loss.backward()
            optimizer.step()

            # print statistics
            running_loss += loss.item()
            if i % 2000 == 1999:    # print every 2000 mini-batches
                print('[%d, %5d] loss: %.3f' %
                    (epoch + 1, i + 1, running_loss / 2000))
                running_loss = 0.0

    print('Finished Training')
